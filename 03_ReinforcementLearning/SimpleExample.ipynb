{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ce89ac1-baa4-45f7-9ace-241b43d3ffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e90412b5-ffe9-4225-a668-ba135b600528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the maze (1 represents walls, 0 represents empty space)\n",
    "maze = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, 0, 0, 1],\n",
    "    [1, 0, 1, 0, 1],\n",
    "    [1, 0, 0, 0, 1],\n",
    "    [1, 1, 1, 1, 1]\n",
    "])\n",
    "\n",
    "# Define the starting position and the goal position\n",
    "start = (1,1)\n",
    "goal = (3,3)\n",
    "\n",
    "# Define the action the robot can take (up, down, left, right)\n",
    "actions = [(0,1), (0,-1), (1,0), (-1,0)]\n",
    "\n",
    "# Initialize the Q-table with zeros\n",
    "q_table = np.zeros((maze.shape[0], maze.shape[1], len(actions)))\n",
    "# print(q_table)\n",
    "\n",
    "# Define parameters\n",
    "learning_rate = 0.1\n",
    "discount_factor = 0.9\n",
    "exploration_rate = 0.1\n",
    "num_episodes = 1000\n",
    "\n",
    "# Define the epsilon-greedy policy\n",
    "def choose_action(state):\n",
    "    if np.random.uniform(0,1) < exploration_rate:\n",
    "        return np.random.choice(len(actions))\n",
    "    else:\n",
    "        return np.argmax(q_table[state])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb21a6ed-dc28-4cbe-982b-792a69d780e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Run the episodes\n",
    "for episode in range(num_episodes):\n",
    "    state = start\n",
    "    while state != goal:\n",
    "        action = choose_action(state)\n",
    "        next_state = (state[0] + actions[action][0], state[1] + actions[action][1])\n",
    "        \n",
    "        # Check if the next_state is within the boundaries of the maze (5x5)\n",
    "        if 0 <= next_state[0] < 5 and 0 <= next_state[1] < 5:\n",
    "            # print(\"current state is : \", state)\n",
    "            # print(\"next state is : \", next_state)\n",
    "            reward = -1 if maze[next_state] == 0 else -5  # Punish hitting walls\n",
    "\n",
    "            # Update Q-table\n",
    "            q_table[state][action] += learning_rate * (reward + \n",
    "                                discount_factor * np.max(q_table[next_state]) - q_table[state][action])\n",
    "            state = next_state\n",
    "        else:\n",
    "            # Handle out-of-bounds movement (e.g., stay in the same state or apply penalty)\n",
    "            # For example, stay in the same state\n",
    "            # print(\"Agent tried to move out of bounds. Staying in the same state.\")\n",
    "            break\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "421b20c4-c9e4-456f-a0d2-8ac664cc68c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larned path:  [(1, 1), (1, 2), (1, 3), (2, 3), (3, 3)]\n"
     ]
    }
   ],
   "source": [
    "# Now, let's see the learned path\n",
    "state = start\n",
    "path = [state]\n",
    "while state != goal:\n",
    "    action = np.argmax(q_table[state])\n",
    "    next_state = (state[0] + actions[action][0], state[1] + actions[action][1])\n",
    "    state = next_state\n",
    "    path.append(state)\n",
    "\n",
    "print(\"Larned path: \", path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
